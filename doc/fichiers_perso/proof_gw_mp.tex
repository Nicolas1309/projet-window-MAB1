\documentclass{article}

\usepackage{tabularx}
\usepackage{graphicx}
\usepackage{url}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{amsmath, amssymb, amsthm, verbatim}
\usepackage{IEEEtrantools}
\usepackage[margin=1in]{geometry}
\usepackage[colorlinks, linkcolor=blue]{hyperref}
\usepackage{epigraph}
\usepackage{mathrsfs}
\usepackage[toc,page]{appendix}
\usepackage{xcolor}
\usepackage{enumitem}

%Pour Ã©crire des algos:
\usepackage{algorithmic, algorithm}
\usepackage{float}

\newcommand{\IR}{\mathbb{R}}
\newcommand{\IN}{\mathbb{N}}
\theoremstyle{plain}
\newtheorem{thm}{Theorem}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{corollary}[thm]{Corollary}

\title{Algorithm for good window mean-payoff in two players games}
\author{Nicolas Lecomte}
\date{\today}

\begin{document}

\maketitle

We fix a two-player game $G = (S_1, S_2, E, w)$ and $l_{max} \in \IN$.

Now, we can define the following:

\[\forall s \in S, C_0(s)=0 \wedge \forall 1 \leqslant i \leqslant l_{max}, C_i(s) =
\begin{cases}
\max_{(s, s') \in E} \{ \max \{w(s, s'), w(s, s') + C_{i-1}(s')\} \} & \text{if } s \in S_1,\\
\min_{(s, s') \in E} \{ \max \{w(s, s'), w(s, s') + C_{i-1}(s')\} \} & \text{if } s \in S_2.
\end{cases}
\]

The main idea behind this definition is that the value $C_i(s)$ denotes the best sum that $\mathcal{P}_1$ can force in at most $i$ steps from the state $s$ in $G$. The following lemma formalizes this intuition.

\begin{lem}
Let $1 \leqslant i \leqslant l_{max}$ and $s \in S$, we have:

\[ C_i(s) = max_{\sigma_1 \in \Lambda_1} min_{\sigma_2 \in \Lambda_2} BestSum_i(Outcome_G(s, \sigma_1, \sigma_2)) \]

where for all $\pi \in Plays_s(G), BestSum_i(\pi) = \max \{n \in \IN | \exists j \leqslant i, \sum_{k=0}^{j-1} w(e_\pi (k, k+1)) \geqslant n \}$. So, $BestSum_i(\pi)$ is the best sum on the weights of the edges along a play $\pi$ within $i$ steps.

\end{lem}

\begin{proof}
We will prove the proposition by induction on $i$. So, let's fix a state $s \in S$.

Basic case: $i = 1$. If $s$ belongs to $S_1$, then $C_1(s) = \max_{(s, s') \in E} w(s, s')$ and, clearly, the best sum that we can see along a play in $1$ step is the biggest weight on an edge leaving $s$. Furthermore, this edge can be taken in a strategy of player 1 and the result does not depend on any strategy of player $2$. A symmetrical argument can be used if $s$ belongs to $S_2$.

Induction step: let $1 \leqslant k < l_{max}$ such that the lemma is true for $i = k$. We will thus show that it is still true for $i = k+1$. Let $s \in S$ a state of the game.

Let $s' \in S$ a successor of $s$ in $G$, we can consider $BS_{k+1}(s, s')$ the best sum that $\mathcal{P}_1$ can ensure in max $k+1$ steps where the first step is the edge $(s, s')$.

If $BS_{k+1}(s, s')$ comes from a path of length $1$, then we have clearly that $BS_{k+1}(s, s')= w(s, s')$.

Now, suppose that $BS_{k+1}(s, s')$ comes from a path of minimal length $2$ and consider $r$ the value such that $BS_{k+1}(s, s') = w(s, s') + r$. So, $r$ is the best sum that can be ensured in max $k$ steps from $s'$ in $G$. Thus, we have that $r = C_k(s')$ by the hypothesis of the induction.

So, it's clear that $BS_{k+1}(s, s') = max\{w(s, s'), w(s, s')+C_k(s')\}$.
There are now two possibilities for $s$:
\begin{itemize}
\item If $s$ belongs to $S_1$, then, player 1 can use the strategy given in the induction hypothesis and plays $(s, s^*)$ such that $BS_{k+1}(s, s^*) = max_{(s, s') \in E} BS_{k+1}(s, s') = C_{k+1}(s)$. This strategy gives the best value because of the induction hypothesis and the maximization of the values $BS_{k+1}(s, s')$.

\item If $s$ belongs to $S_2$, then a similar argument can show that $C_{k+1}(s)$ is the best sum that $\mathcal{P}_1$ can ensure in at most $k+1$ steps from $s$ in $G$.
\end{itemize}
\end{proof}

\begin{prop}
We have, for all state $s \in S$:
\[C_{l_{max}}(s) \geqslant 0 \Leftrightarrow \text{ s is a winning state in G for $\mathcal{P}_1$ for the winodw objective } GW_{MP}(G, l_{max})\]
\end{prop}

\begin{proof}
Let $s \in S$ a state of the game,\\
We have the following equivalences:
\begin{align*}
C_{l_{max}}(s) \geqslant 0 &\Leftrightarrow max_{\sigma_1 \in \Lambda_1} min_{\sigma_2 \in \Lambda_2} BestSum_{l_{max}}(Outcome_G(s, \sigma_1, \sigma_2)) \geqslant 0\\
						   &\Leftrightarrow \exists \sigma_1 \in \Lambda_1, \forall \sigma_2 \in \Lambda_2, BestSum_{l_{max}}(Outcome_G(s, \sigma_1, \sigma_2)) \geqslant 0\\
						   &\Leftrightarrow \exists \sigma_1 \in \Lambda_1, \forall \sigma_2 \in \Lambda_2, \exists n \in \IN, \exists j \leqslant l_{max}, \sum_{k=0}^{l_{max}-1} w(e_{Outcome_G(s, \sigma_1, \sigma_2)} (k, k+1)) \geqslant n\\
						   &\Leftrightarrow \exists \sigma_1 \in \Lambda_1, \forall \sigma_2 \in \Lambda_2, \exists j \leqslant l_{max}, \sum_{k=0}^{l_{max}-1} w(e_{Outcome_G(s, \sigma_1, \sigma_2)} (k, k+1)) \geqslant 0\\
						   &\Leftrightarrow \exists \sigma_1 \in \Lambda_1, \forall \sigma_2 \in \Lambda_2, Outcome_G(s, \sigma_1, \sigma_2) \in GW_{MP}(G, l_{max})\\
						   &\Leftrightarrow \text{ s is a winning state in G for $\mathcal{P}_1$ for the objective } GW_{MP}(G, l_{max})
\end{align*}

\end{proof}

\end{document}

















